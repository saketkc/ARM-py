

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Chapter 4 Linear regression: before and after fitting the model &#8212; Data Analysis Using Regression and Multilevel/Hierarchjial Models - Andrew Gelman &amp; Jennifer Hill</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Chapter 3 - Linear regression: the basics" href="03_Chapter03_Linear_regression_the_basics.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">Data Analysis Using Regression and Multilevel/Hierarchjial Models - Andrew Gelman & Jennifer Hill</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../intro.html">Data Analysis Using Regression and Multilevel/Hierarchial Models in Python</a>
  </li>
  <li class="">
    <a href="02_Chapter02_Basic_Probability_and_Statistics.html">Chapter 2 - Concepts and methods from basic probability and statistics</a>
  </li>
  <li class="">
    <a href="03_Chapter03_Linear_regression_the_basics.html">Chapter 3 - Linear regression: the basics</a>
  </li>
  <li class="active">
    <a href="">Chapter 4 Linear regression: before and after fitting the model</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
                    class="fas fa-download"></i></button>

            
            <div class="dropdown-buttons">
                <!-- ipynb file if we had a myst markdown file -->
                
                <!-- Download raw file -->
                <a class="dropdown-buttons" href="../_sources/Chapters/04_Chapter04_Linear_regresion_before_and_after_fitting_the_model.ipynb"><button type="button"
                        class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                        data-placement="left">.ipynb</button></a>
                <!-- Download PDF via print -->
                <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                    onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
            </div>
            
        </div>

        <!-- Source interaction buttons -->
        

        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->
        
    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="chapter-4-linear-regression-before-and-after-fitting-the-model">
<h1>Chapter 4 Linear regression: before and after fitting the model<a class="headerlink" href="#chapter-4-linear-regression-before-and-after-fitting-the-model" title="Permalink to this headline">Â¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">proplot</span> <span class="k">as</span> <span class="nn">plot</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="n">pylab</span> <span class="n">inline</span>


<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;axes.labelweight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;bold&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;font.weight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;bold&quot;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Populating the interactive namespace from numpy and matplotlib
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">earnings_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/earnings/heights.tsv.gz&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">earnings_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>earn</th>
      <th>height1</th>
      <th>height2</th>
      <th>sex</th>
      <th>race</th>
      <th>hisp</th>
      <th>ed</th>
      <th>yearbn</th>
      <th>height</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NaN</td>
      <td>5.0</td>
      <td>6.0</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>12</td>
      <td>53</td>
      <td>66.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>12</td>
      <td>50</td>
      <td>64.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>50000.0</td>
      <td>6.0</td>
      <td>2.0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>16</td>
      <td>45</td>
      <td>74.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>60000.0</td>
      <td>5.0</td>
      <td>6.0</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>16</td>
      <td>32</td>
      <td>66.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>30000.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>16</td>
      <td>61</td>
      <td>64.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">earnings_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(2029, 9)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">earnings_df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(1379, 9)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">earnings_df</span> <span class="o">=</span> <span class="n">earnings_df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">earnings_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(1379, 9)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">earnings_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>earn</th>
      <th>height1</th>
      <th>height2</th>
      <th>sex</th>
      <th>race</th>
      <th>hisp</th>
      <th>ed</th>
      <th>yearbn</th>
      <th>height</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>50000.0</td>
      <td>6.0</td>
      <td>2.0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>16</td>
      <td>45</td>
      <td>74.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>60000.0</td>
      <td>5.0</td>
      <td>6.0</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>16</td>
      <td>32</td>
      <td>66.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>30000.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>16</td>
      <td>61</td>
      <td>64.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>50000.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>2</td>
      <td>3</td>
      <td>2</td>
      <td>16</td>
      <td>99</td>
      <td>63.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>51000.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>17</td>
      <td>51</td>
      <td>63.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="centering-and-standardizing-especially-for-models-with-interactions">
<h1>Centering and standardizing, especially for models with interactions<a class="headerlink" href="#centering-and-standardizing-especially-for-models-with-interactions" title="Permalink to this headline">Â¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kidiq_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/kidiq.tsv.gz&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">kidiq_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>kid_score</th>
      <th>mom_hs</th>
      <th>mom_iq</th>
      <th>mom_work</th>
      <th>mom_age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>65</td>
      <td>1.0</td>
      <td>121.117529</td>
      <td>4</td>
      <td>27</td>
    </tr>
    <tr>
      <th>1</th>
      <td>98</td>
      <td>1.0</td>
      <td>89.361882</td>
      <td>4</td>
      <td>25</td>
    </tr>
    <tr>
      <th>2</th>
      <td>85</td>
      <td>1.0</td>
      <td>115.443165</td>
      <td>4</td>
      <td>27</td>
    </tr>
    <tr>
      <th>3</th>
      <td>83</td>
      <td>1.0</td>
      <td>99.449639</td>
      <td>3</td>
      <td>25</td>
    </tr>
    <tr>
      <th>4</th>
      <td>115</td>
      <td>1.0</td>
      <td>92.745710</td>
      <td>4</td>
      <td>27</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq&quot;&quot;&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">kidiq_df</span>
<span class="p">)</span>
<span class="n">results_hs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_hs</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">results_hs</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:              kid_score   R-squared:                       0.230
Model:                            OLS   Adj. R-squared:                  0.225
Method:                 Least Squares   F-statistic:                     42.84
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           3.07e-24
Time:                        23:35:23   Log-Likelihood:                -1867.5
No. Observations:                 434   AIC:                             3743.
Df Residuals:                     430   BIC:                             3759.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          t      P&gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept       -11.4820     13.758     -0.835      0.404     -38.523      15.559
mom_hs           51.2682     15.338      3.343      0.001      21.122      81.414
mom_iq            0.9689      0.148      6.531      0.000       0.677       1.260
mom_hs:mom_iq    -0.4843      0.162     -2.985      0.003      -0.803      -0.165
==============================================================================
Omnibus:                        8.014   Durbin-Watson:                   1.660
Prob(Omnibus):                  0.018   Jarque-Bera (JB):                8.258
Skew:                          -0.333   Prob(JB):                       0.0161
Kurtosis:                       2.887   Cond. No.                     3.10e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.1e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
Residual SD: 17.91
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="centering-by-subtracting-the-mean">
<h1>Centering by subtracting the mean<a class="headerlink" href="#centering-by-subtracting-the-mean" title="Permalink to this headline">Â¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_hs_centered&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_hs&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_hs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_iq_centered&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_iq&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_iq&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;kid_score ~ mom_hs_centered + mom_iq_centered + mom_hs_centered:mom_iq_centered&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">kidiq_df</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">results_hs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_hs</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">results_hs</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:              kid_score   R-squared:                       0.230
Model:                            OLS   Adj. R-squared:                  0.225
Method:                 Least Squares   F-statistic:                     42.84
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           3.07e-24
Time:                        23:35:23   Log-Likelihood:                -1867.5
No. Observations:                 434   AIC:                             3743.
Df Residuals:                     430   BIC:                             3759.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
===================================================================================================
                                      coef    std err          t      P&gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------------------------
Intercept                          87.6389      0.908     96.565      0.000      85.855      89.423
mom_hs_centered                     2.8408      2.427      1.171      0.242      -1.929       7.610
mom_iq_centered                     0.5884      0.061      9.712      0.000       0.469       0.707
mom_hs_centered:mom_iq_centered    -0.4843      0.162     -2.985      0.003      -0.803      -0.165
==============================================================================
Omnibus:                        8.014   Durbin-Watson:                   1.660
Prob(Omnibus):                  0.018   Jarque-Bera (JB):                8.258
Skew:                          -0.333   Prob(JB):                       0.0161
Kurtosis:                       2.887   Cond. No.                         42.2
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Residual SD: 17.91
</pre></div>
</div>
</div>
</div>
<p>The residual SD and <span class="math notranslate nohighlight">\(R^2\)</span> do not change as a linear transformation does not affect the fit. Interpretation:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Intercept (87): Score of children with  mothers who have an average IQ and have gone to a &quot;mean high school&quot; 
- Coeff of mom_hs (2.8): Score of children differes by 2.8 for children with mother&#39;s mean high school difference of 1 (i.e. went to school vs didn&#39;t) as long as they have the same mean IQ.
- Coeff of mom_iq (0.6): Score of children will differ by 0.6 for a 1 point difference in mother&#39;s IQ if they are at the same average level of &quot;mean high school&quot;
- Interaction effect: Difference in slope for mom_iq comparing children with mothers who did and did not complete 
</pre></div>
</div>
<p>Coefficient of each main effect corresponds to the predictive difference with the other input at its average value.</p>
</div>
<div class="section" id="using-a-conventional-centering-point">
<h1>Using a conventional centering point<a class="headerlink" href="#using-a-conventional-centering-point" title="Permalink to this headline">Â¶</a></h1>
<p>If we center on an understandable reference - the above values are more interpretable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_hs_centered2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_hs&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mf">0.5</span>
<span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_iq_centered2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_iq&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">100</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;kid_score ~ mom_hs_centered2 + mom_iq_centered2 + mom_hs_centered2:mom_iq_centered2&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">kidiq_df</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">results_hs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_hs</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">results_hs</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:              kid_score   R-squared:                       0.230
Model:                            OLS   Adj. R-squared:                  0.225
Method:                 Least Squares   F-statistic:                     42.84
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           3.07e-24
Time:                        23:35:23   Log-Likelihood:                -1867.5
No. Observations:                 434   AIC:                             3743.
Df Residuals:                     430   BIC:                             3759.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================================
                                        coef    std err          t      P&gt;|t|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            86.8273      1.213     71.561      0.000      84.442      89.212
mom_hs_centered2                      2.8408      2.427      1.171      0.242      -1.929       7.610
mom_iq_centered2                      0.7268      0.081      8.960      0.000       0.567       0.886
mom_hs_centered2:mom_iq_centered2    -0.4843      0.162     -2.985      0.003      -0.803      -0.165
==============================================================================
Omnibus:                        8.014   Durbin-Watson:                   1.660
Prob(Omnibus):                  0.018   Jarque-Bera (JB):                8.258
Skew:                          -0.333   Prob(JB):                       0.0161
Kurtosis:                       2.887   Cond. No.                         46.9
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Residual SD: 17.91
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Coefficient of mom_hs_centered2 is the average predictive difference between a child with mom.hs = 1 and mom.hs = 0 for those children with mom.iq = 100.</p></li>
<li><p>Coefficient of mom_iq_centered2 is the average predictive difference between a child with mom.iq = 0.5</p></li>
</ul>
</div>
<div class="section" id="standardizing-by-subtracting-the-mean-and-dividing-by-2-standard-deviations">
<h1>Standardizing by subtracting the mean and dividing by 2 standard deviations<a class="headerlink" href="#standardizing-by-subtracting-the-mean-and-dividing-by-2-standard-deviations" title="Permalink to this headline">Â¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_hs_centeredZ&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_hs&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_hs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_hs&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_iq_centeredZ&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">(</span><span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_iq&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_iq&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">kidiq_df</span><span class="p">[</span><span class="s2">&quot;mom_iq&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="p">)</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;kid_score ~ mom_hs_centeredZ + mom_iq_centeredZ + mom_hs_centeredZ:mom_iq_centeredZ&quot;&quot;&quot;</span><span class="p">,</span>
    <span class="n">data</span><span class="o">=</span><span class="n">kidiq_df</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">results_hs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_hs</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">results_hs</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:              kid_score   R-squared:                       0.230
Model:                            OLS   Adj. R-squared:                  0.225
Method:                 Least Squares   F-statistic:                     42.84
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           3.07e-24
Time:                        23:35:23   Log-Likelihood:                -1867.5
No. Observations:                 434   AIC:                             3743.
Df Residuals:                     430   BIC:                             3759.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=====================================================================================================
                                        coef    std err          t      P&gt;|t|      [0.025      0.975]
-----------------------------------------------------------------------------------------------------
Intercept                            87.6389      0.908     96.565      0.000      85.855      89.423
mom_hs_centeredZ                     13.8304     11.814      1.171      0.242      -9.391      37.051
mom_iq_centeredZ                      0.0785      0.008      9.712      0.000       0.063       0.094
mom_hs_centeredZ:mom_iq_centeredZ    -0.3144      0.105     -2.985      0.003      -0.521      -0.107
==============================================================================
Omnibus:                        8.014   Durbin-Watson:                   1.660
Prob(Omnibus):                  0.018   Jarque-Bera (JB):                8.258
Skew:                          -0.333   Prob(JB):                       0.0161
Kurtosis:                       2.887   Cond. No.                     1.54e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.54e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
Residual SD: 17.91
</pre></div>
</div>
</div>
</div>
<div class="section" id="why-scale-by-2-standard-deviations">
<h2>Why scale by 2 standard deviations?<a class="headerlink" href="#why-scale-by-2-standard-deviations" title="Permalink to this headline">Â¶</a></h2>
<p>If <span class="math notranslate nohighlight">\(x\)</span> was a binary variable them its standard deviation is given by $\sqrt{0.5 \times 0.5}= 0.5 $.
If we do not divide by 2, the difference between the extremities of the binary variable  <span class="math notranslate nohighlight">\((0.5/0.5) - (-0.5/0.5) = 2\)</span> and hence the coefficient would correspond half the difference between the two possible values of x. While dividing by 2 will result in a difference of 1.</p>
</div>
</div>
<div class="section" id="logarithmic-transformations">
<h1>Logarithmic transformations<a class="headerlink" href="#logarithmic-transformations" title="Permalink to this headline">Â¶</a></h1>
<p>A linear model on the logarithmic scale corresponds to a multiplicative model on the original scale.</p>
<div class="section" id="height-and-earnings-example">
<h2>Height and earnings example<a class="headerlink" href="#height-and-earnings-example" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;log_earn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;earn&quot;</span><span class="p">])</span>
<span class="n">earnings_df</span> <span class="o">=</span> <span class="n">earnings_df</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

<span class="n">earnings_df</span> <span class="o">=</span> <span class="n">earnings_df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">earn_log_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;log_earn ~ height&quot;&quot;&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">earnings_df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">earn_log_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:               log_earn   R-squared:                       0.060
Model:                            OLS   Adj. R-squared:                  0.060
Method:                 Least Squares   F-statistic:                     76.44
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           7.62e-18
Time:                        23:35:23   Log-Likelihood:                -1555.6
No. Observations:                1192   AIC:                             3115.
Df Residuals:                    1190   BIC:                             3125.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      5.7785      0.451     12.815      0.000       4.894       6.663
height         0.0588      0.007      8.743      0.000       0.046       0.072
==============================================================================
Omnibus:                      223.552   Durbin-Watson:                   1.904
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              457.878
Skew:                          -1.079   Prob(JB):                    3.74e-100
Kurtosis:                       5.136   Cond. No.                     1.17e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.17e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
</pre></div>
</div>
</div>
</div>
<div class="section" id="interpretation">
<h3>Interpretation<a class="headerlink" href="#interpretation" title="Permalink to this headline">Â¶</a></h3>
<p>A coefficient of 0.06 on log scale for height implies a unit change in height will lead to <span class="math notranslate nohighlight">\(\exp{0.06}= 1.06\)</span> difference in earnings. Thus a change of 1 unit in height leads to a change of 6% in earnings.</p>
</div>
<div class="section" id="why-use-a-natural-log-instead-of-log-10">
<h3>Why use a natural log instead of <span class="math notranslate nohighlight">\(log_{10}\)</span><a class="headerlink" href="#why-use-a-natural-log-instead-of-log-10" title="Permalink to this headline">Â¶</a></h3>
<p>Coefficients on the natural-log scale are âmoreâ interpretable. A coefficient of <span class="math notranslate nohighlight">\(0.06\)</span> for example corresponds to
a change of 6%. On the other hand, a change on <span class="math notranslate nohighlight">\(\log_{10}\)</span> scale is harder to interpret:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;log10_earn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;earn&quot;</span><span class="p">])</span>
<span class="n">earnings_df</span> <span class="o">=</span> <span class="n">earnings_df</span><span class="o">.</span><span class="n">replace</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>

<span class="n">earnings_df</span> <span class="o">=</span> <span class="n">earnings_df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">earn_log_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;log10_earn ~ height&quot;&quot;&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">earnings_df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">earn_log_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">earn_log_model</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:             log10_earn   R-squared:                       0.060
Model:                            OLS   Adj. R-squared:                  0.060
Method:                 Least Squares   F-statistic:                     76.44
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           7.62e-18
Time:                        23:35:23   Log-Likelihood:                -561.42
No. Observations:                1192   AIC:                             1127.
Df Residuals:                    1190   BIC:                             1137.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      2.5096      0.196     12.815      0.000       2.125       2.894
height         0.0255      0.003      8.743      0.000       0.020       0.031
==============================================================================
Omnibus:                      223.552   Durbin-Watson:                   1.904
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              457.878
Skew:                          -1.079   Prob(JB):                    3.74e-100
Kurtosis:                       5.136   Cond. No.                     1.17e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.17e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
Residual SD: 0.39
</pre></div>
</div>
</div>
</div>
<p>A coefficient of <span class="math notranslate nohighlight">\(0.0255\)</span> is less interpretable here as it still corresponds to a change of <span class="math notranslate nohighlight">\(10^{0.0255} = 1.062\)</span></p>
</div>
</div>
<div class="section" id="building-a-regression-model-on-the-log-scale">
<h2>Building a regression model on the log scale<a class="headerlink" href="#building-a-regression-model-on-the-log-scale" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;male&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># Set rows where sex==2 to female (0)</span>
<span class="n">earnings_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">earnings_df</span><span class="o">.</span><span class="n">sex</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;male&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">earn_log_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;log_earn ~ height + male&quot;&quot;&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">earnings_df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">earn_log_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">earn_log_model</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:               log_earn   R-squared:                       0.087
Model:                            OLS   Adj. R-squared:                  0.085
Method:                 Least Squares   F-statistic:                     56.34
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           4.21e-24
Time:                        23:35:23   Log-Likelihood:                -1538.7
No. Observations:                1192   AIC:                             3083.
Df Residuals:                    1189   BIC:                             3099.
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      8.1527      0.603     13.530      0.000       6.970       9.335
height         0.0207      0.009      2.218      0.027       0.002       0.039
male           0.4232      0.072      5.841      0.000       0.281       0.565
==============================================================================
Omnibus:                      225.577   Durbin-Watson:                   1.889
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              462.608
Skew:                          -1.088   Prob(JB):                    3.52e-101
Kurtosis:                       5.141   Cond. No.                     1.59e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.59e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
Residual SD: 0.88
</pre></div>
</div>
</div>
</div>
<div class="section" id="including-an-interaction">
<h3>Including an interaction<a class="headerlink" href="#including-an-interaction" title="Permalink to this headline">Â¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;male&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># Set rows where sex==2 to female (0)</span>
<span class="n">earnings_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">earnings_df</span><span class="o">.</span><span class="n">sex</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;male&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">earn_log_model3</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;log_earn ~ height + male + height:male&quot;&quot;&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">earnings_df</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">earn_log_model3</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">earn_log_model3</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:               log_earn   R-squared:                       0.087
Model:                            OLS   Adj. R-squared:                  0.084
Method:                 Least Squares   F-statistic:                     37.58
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           3.32e-23
Time:                        23:35:23   Log-Likelihood:                -1538.6
No. Observations:                1192   AIC:                             3085.
Df Residuals:                    1188   BIC:                             3106.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
Intercept       8.3885      0.844      9.945      0.000       6.734      10.043
height          0.0170      0.013      1.304      0.193      -0.009       0.043
male           -0.0786      1.258     -0.062      0.950      -2.546       2.389
height:male     0.0074      0.019      0.400      0.690      -0.029       0.044
==============================================================================
Omnibus:                      225.961   Durbin-Watson:                   1.889
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              463.655
Skew:                          -1.089   Prob(JB):                    2.08e-101
Kurtosis:                       5.143   Cond. No.                     4.16e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.16e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
Residual SD: 0.88
</pre></div>
</div>
</div>
</div>
<p>Interpretation:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Intercept = Predicted log earning when height and male is zero (which is non feasible hence not interpretable)
- Coeff of height (0.017) = Predicted difference in log earnings corresponding to a 1-inch difference in height if male = 0 =&gt; The estimated predictive difference in earnings for a 1-inch difference in height is 1.7% for women.
- Coeff of male (-0.0786): Predicted difference in log earnings between women and men if height equals 0. But heights are never zero so this is not interpretable.
- Interaction term height:male (0.0074): Predictive difference in log earnings comparing men to women =&gt; An inch of height difference corresponds to 0.7% more of an in increase in earnings among men than among women and the estimated predictive difference in log earnings is 1.7% + 0.7% = 2.4% per inch of height in men.
</pre></div>
</div>
</div>
<div class="section" id="linear-transformation-to-make-coefficients-more-interpretable">
<h3>Linear transformation to make coefficients more interpretable:<a class="headerlink" href="#linear-transformation-to-make-coefficients-more-interpretable" title="Permalink to this headline">Â¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;height_z&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="p">)</span> <span class="o">/</span> <span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">earn_log_model4</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span>
    <span class="n">formula</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;log_earn ~ height_z + male + height_z:male&quot;&quot;&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">earnings_df</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">earn_log_model4</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">earn_log_model4</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">earnings_df</span><span class="p">[</span><span class="s2">&quot;height&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:               log_earn   R-squared:                       0.087
Model:                            OLS   Adj. R-squared:                  0.084
Method:                 Least Squares   F-statistic:                     37.58
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           3.32e-23
Time:                        23:35:23   Log-Likelihood:                -1538.6
No. Observations:                1192   AIC:                             3085.
Df Residuals:                    1188   BIC:                             3106.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
=================================================================================
                    coef    std err          t      P&gt;|t|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept         9.5266      0.045    210.878      0.000       9.438       9.615
height_z          0.0654      0.050      1.304      0.193      -0.033       0.164
male              0.4197      0.073      5.748      0.000       0.276       0.563
height_z:male     0.0286      0.072      0.400      0.690      -0.112       0.169
==============================================================================
Omnibus:                      225.961   Durbin-Watson:                   1.889
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              463.655
Skew:                          -1.089   Prob(JB):                    2.08e-101
Kurtosis:                       5.143   Cond. No.                         4.64
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Residual SD: 0.88
66.91694630872483 3.846637848956869
</pre></div>
</div>
</div>
</div>
<p>Interpretation:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Intercept = Predicted log earning when height is average height and male is zero (which is non feasible hence not interpretable) =&gt; 66.9 inch women has a log earnings of 9.52
- Coeff of height (0.065) = Predicted difference in log earnings corresponding to a 1-inch standard deviation in height if male = 0 =&gt; The estimated predictive difference in earnings for a 3.8 inch difference in height of females is 6% for women.
- Coeff of male (0.4197): Predicted difference in log earnings between women and men if height equals 66.9 inches. Thus, males of height 66.9 inches are expected to have 41.9% higher log earning than women
- Interaction term height:male (0.0286): Predictive difference in log earnings comparing men to women =&gt; A 2.8 inch of height difference corresponds to 2.8% more of an in increase in earnings among men than among women and the estimated predictive difference in log earnings is 41.9% + 2.7% = 44.6% per inch of height in men.
</pre></div>
</div>
</div>
</div>
<div class="section" id="using-discrete-rather-than-continous-predictors">
<h2>Using discrete rather than continous predictors<a class="headerlink" href="#using-discrete-rather-than-continous-predictors" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kid_score_momwork</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;kid_score ~ C(mom_work)&quot;&quot;&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">kidiq_df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">kid_score_momwork</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">kid_score_momwork</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:              kid_score   R-squared:                       0.024
Model:                            OLS   Adj. R-squared:                  0.018
Method:                 Least Squares   F-statistic:                     3.590
Date:                Sat, 20 Jun 2020   Prob (F-statistic):             0.0138
Time:                        23:35:24   Log-Likelihood:                -1918.9
No. Observations:                 434   AIC:                             3846.
Df Residuals:                     430   BIC:                             3862.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
====================================================================================
                       coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept           82.0000      2.305     35.568      0.000      77.469      86.531
C(mom_work)[T.2]     3.8542      3.095      1.245      0.214      -2.229       9.937
C(mom_work)[T.3]    11.5000      3.553      3.237      0.001       4.517      18.483
C(mom_work)[T.4]     5.2098      2.704      1.927      0.055      -0.105      10.524
==============================================================================
Omnibus:                       12.371   Durbin-Watson:                   1.477
Prob(Omnibus):                  0.002   Jarque-Bera (JB):               12.950
Skew:                          -0.411   Prob(JB):                      0.00154
Kurtosis:                       2.796   Cond. No.                         5.92
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Residual SD: 20.16
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="building-regression-models-for-prediction">
<h1>Building regression models for prediction<a class="headerlink" href="#building-regression-models-for-prediction" title="Permalink to this headline">Â¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mesquite_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../data/mesquite/mesquite.tsv.gz&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">mesquite_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Obs</th>
      <th>Group</th>
      <th>Diam1</th>
      <th>Diam2</th>
      <th>TotHt</th>
      <th>CanHt</th>
      <th>Dens</th>
      <th>LeafWt</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>MCD</td>
      <td>1.8</td>
      <td>1.15</td>
      <td>1.30</td>
      <td>1.00</td>
      <td>1</td>
      <td>401.3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>MCD</td>
      <td>1.7</td>
      <td>1.35</td>
      <td>1.35</td>
      <td>1.33</td>
      <td>1</td>
      <td>513.7</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>MCD</td>
      <td>2.8</td>
      <td>2.55</td>
      <td>2.16</td>
      <td>0.60</td>
      <td>1</td>
      <td>1179.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>MCD</td>
      <td>1.3</td>
      <td>0.85</td>
      <td>1.80</td>
      <td>1.20</td>
      <td>1</td>
      <td>308.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>MCD</td>
      <td>3.3</td>
      <td>1.90</td>
      <td>1.55</td>
      <td>1.05</td>
      <td>1</td>
      <td>855.2</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;LeafWt ~ Diam1 + Diam2 + CanHt + TotHt + Dens + Group&quot;&quot;&quot;</span>
<span class="n">mesquite_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">mesquite_df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mesquite_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mesquite_model</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 LeafWt   R-squared:                       0.848
Model:                            OLS   Adj. R-squared:                  0.825
Method:                 Least Squares   F-statistic:                     36.34
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           1.73e-14
Time:                        23:35:24   Log-Likelihood:                -318.82
No. Observations:                  46   AIC:                             651.6
Df Residuals:                      39   BIC:                             664.4
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
================================================================================
                   coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept    -1091.8880    176.456     -6.188      0.000   -1448.804    -734.972
Group[T.MCD]   363.2951    100.184      3.626      0.001     160.654     565.936
Diam1          189.6690    112.760      1.682      0.101     -38.410     417.748
Diam2          371.4621    124.378      2.987      0.005     119.883     623.041
CanHt          355.6653    209.843      1.695      0.098     -68.782     780.113
TotHt         -101.7325    185.574     -0.548      0.587    -477.091     273.626
Dens           131.2542     34.355      3.820      0.000      61.764     200.744
==============================================================================
Omnibus:                        9.865   Durbin-Watson:                   2.137
Prob(Omnibus):                  0.007   Jarque-Bera (JB):               19.723
Skew:                           0.366   Prob(JB):                     5.21e-05
Kurtosis:                       6.123   Cond. No.                         26.9
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Residual SD: 250.39
</pre></div>
</div>
</div>
</div>
<div class="section" id="multiplicative-model">
<h2>Multiplicative Model<a class="headerlink" href="#multiplicative-model" title="Permalink to this headline">Â¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;log(LeafWt) ~ log(Diam1) + log(Diam2) + log(CanHt) + log(TotHt) + log(Dens) + Group&quot;&quot;&quot;</span>
<span class="n">mesquite_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">mesquite_df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mesquite_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mesquite_model</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:            log(LeafWt)   R-squared:                       0.887
Model:                            OLS   Adj. R-squared:                  0.870
Method:                 Least Squares   F-statistic:                     51.17
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           5.73e-17
Time:                        23:35:24   Log-Likelihood:                -10.406
No. Observations:                  46   AIC:                             34.81
Df Residuals:                      39   BIC:                             47.61
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
================================================================================
                   coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        4.7680      0.155     30.747      0.000       4.454       5.082
Group[T.MCD]     0.5834      0.129      4.534      0.000       0.323       0.844
log(Diam1)       0.3938      0.282      1.397      0.170      -0.177       0.964
log(Diam2)       1.1512      0.210      5.477      0.000       0.726       1.576
log(CanHt)       0.3732      0.281      1.330      0.191      -0.194       0.941
log(TotHt)       0.3943      0.313      1.260      0.215      -0.239       1.027
log(Dens)        0.1093      0.122      0.896      0.376      -0.137       0.356
==============================================================================
Omnibus:                        1.935   Durbin-Watson:                   1.362
Prob(Omnibus):                  0.380   Jarque-Bera (JB):                1.047
Skew:                          -0.283   Prob(JB):                        0.593
Kurtosis:                       3.474   Cond. No.                         12.6
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Residual SD: 0.31
</pre></div>
</div>
</div>
</div>
<p>Interpretation =&gt; A difference of x% in canopy height leads to a difference of 0.37x% difference in leaf weight.</p>
<p>The above model is a complicated one. Maybe we can start with something very simple.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mesquite_df</span><span class="p">[</span><span class="s2">&quot;CanVol&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mesquite_df</span><span class="p">[</span><span class="s1">&#39;Diam1&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">mesquite_df</span><span class="p">[</span><span class="s1">&#39;Diam2&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">mesquite_df</span><span class="p">[</span><span class="s1">&#39;CanHt&#39;</span><span class="p">]</span> 
<span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;log(LeafWt) ~ log(CanVol)&quot;&quot;&quot;</span>
<span class="n">mesquite_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">mesquite_df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mesquite_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mesquite_model</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:            log(LeafWt)   R-squared:                       0.799
Model:                            OLS   Adj. R-squared:                  0.795
Method:                 Least Squares   F-statistic:                     175.1
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           6.09e-17
Time:                        23:35:24   Log-Likelihood:                -23.687
No. Observations:                  46   AIC:                             51.37
Df Residuals:                      44   BIC:                             55.03
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------
Intercept       5.1697      0.083     62.066      0.000       5.002       5.338
log(CanVol)     0.7224      0.055     13.234      0.000       0.612       0.832
==============================================================================
Omnibus:                        2.765   Durbin-Watson:                   0.996
Prob(Omnibus):                  0.251   Jarque-Bera (JB):                2.066
Skew:                          -0.515   Prob(JB):                        0.356
Kurtosis:                       3.125   Cond. No.                         2.59
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Residual SD: 0.41
</pre></div>
</div>
</div>
</div>
<p>So leaf weight is approximately proportional to 0.72th power to Canopy Volume. It has a impressive <span class="math notranslate nohighlight">\(R^2\)</span> of 0.8</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mesquite_df</span><span class="p">[</span><span class="s2">&quot;CanVol&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mesquite_df</span><span class="p">[</span><span class="s1">&#39;Diam1&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">mesquite_df</span><span class="p">[</span><span class="s1">&#39;Diam2&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">mesquite_df</span><span class="p">[</span><span class="s1">&#39;CanHt&#39;</span><span class="p">]</span> 
<span class="n">mesquite_df</span><span class="p">[</span><span class="s2">&quot;CanArea&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mesquite_df</span><span class="p">[</span><span class="s1">&#39;Diam1&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">mesquite_df</span><span class="p">[</span><span class="s1">&#39;Diam2&#39;</span><span class="p">]</span>
<span class="n">mesquite_df</span><span class="p">[</span><span class="s2">&quot;Shape&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mesquite_df</span><span class="p">[</span><span class="s1">&#39;Diam1&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">mesquite_df</span><span class="p">[</span><span class="s1">&#39;Diam2&#39;</span><span class="p">]</span>

<span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;log(LeafWt) ~ log(CanVol) + log(CanArea) + log(Shape) + log(TotHt) + log(Dens) + Group&quot;&quot;&quot;</span>

<span class="n">mesquite_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">mesquite_df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mesquite_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mesquite_model</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:            log(LeafWt)   R-squared:                       0.887
Model:                            OLS   Adj. R-squared:                  0.870
Method:                 Least Squares   F-statistic:                     51.17
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           5.73e-17
Time:                        23:35:24   Log-Likelihood:                -10.406
No. Observations:                  46   AIC:                             34.81
Df Residuals:                      39   BIC:                             47.61
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
================================================================================
                   coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        4.7680      0.155     30.747      0.000       4.454       5.082
Group[T.MCD]     0.5834      0.129      4.534      0.000       0.323       0.844
log(CanVol)      0.3732      0.281      1.330      0.191      -0.194       0.941
log(CanArea)     0.3993      0.294      1.357      0.183      -0.196       0.994
log(Shape)      -0.3787      0.231     -1.642      0.109      -0.845       0.088
log(TotHt)       0.3943      0.313      1.260      0.215      -0.239       1.027
log(Dens)        0.1093      0.122      0.896      0.376      -0.137       0.356
==============================================================================
Omnibus:                        1.935   Durbin-Watson:                   1.362
Prob(Omnibus):                  0.380   Jarque-Bera (JB):                1.047
Skew:                          -0.283   Prob(JB):                        0.593
Kurtosis:                       3.474   Cond. No.                         22.2
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Residual SD: 0.31
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">formula</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;log(LeafWt) ~ log(CanVol) + log(CanArea) + Group&quot;&quot;&quot;</span>

<span class="n">mesquite_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">mesquite_df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mesquite_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Residual SD: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mesquite_model</span><span class="o">.</span><span class="n">resid</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="mi">2</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:            log(LeafWt)   R-squared:                       0.873
Model:                            OLS   Adj. R-squared:                  0.864
Method:                 Least Squares   F-statistic:                     96.01
Date:                Sat, 20 Jun 2020   Prob (F-statistic):           7.79e-19
Time:                        23:35:24   Log-Likelihood:                -13.198
No. Observations:                  46   AIC:                             34.40
Df Residuals:                      42   BIC:                             41.71
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
================================================================================
                   coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept        4.6975      0.118     39.812      0.000       4.459       4.936
Group[T.MCD]     0.5269      0.116      4.558      0.000       0.294       0.760
log(CanVol)      0.6148      0.191      3.215      0.003       0.229       1.001
log(CanArea)     0.2889      0.238      1.215      0.231      -0.191       0.768
==============================================================================
Omnibus:                        1.398   Durbin-Watson:                   1.282
Prob(Omnibus):                  0.497   Jarque-Bera (JB):                0.694
Skew:                          -0.261   Prob(JB):                        0.707
Kurtosis:                       3.300   Cond. No.                         13.3
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
Residual SD: 0.33
</pre></div>
</div>
</div>
</div>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="03_Chapter03_Linear_regression_the_basics.html" title="previous page">Chapter 3 - Linear regression: the basics</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Saket Choudhary<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>